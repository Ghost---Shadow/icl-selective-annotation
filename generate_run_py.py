import argparse
import json
import subprocess
from constants import TASK_NAMES, SELECTIVE_ANNOTATION_METHODS

IMPORT_COMMAND = """# Autogenerated with generate_run_py.py
from cvar_pyutils.ccc import submit_dependant_jobs

"""

INVOKE_COMMAND = """
submit_dependant_jobs(
    number_of_rolling_jobs=78,
    command_to_run=run_commands,
    machine_type="x86",
    conda_env="cords",
    out_file="out.txt",
    err_file="err.txt",
    queue="nonstandard",
    time="12h",
    num_cores=4,
    num_gpus=1,
    mem="120g",
    gpu_type="a100_40gb",
    mail_log_file_when_done="krishnateja.k@ibm.com",
    mail_notification_on_start="krishnateja.k@ibm.com",
)
"""


def main(model_name):
    with open("run.py", "w") as file:
        file.write(IMPORT_COMMAND)

        all_commands = []
        for task in TASK_NAMES:
            for method in SELECTIVE_ANNOTATION_METHODS:
                command = f"python main.py --task_name {task} --selective_annotation_method {method} "
                command += f"--model_cache_dir models --data_cache_dir datasets "
                command += (
                    f"--output_dir outputs/{task}/{method} --model_name={model_name}\n"
                )
                all_commands.append(command)

        all_commands.append("python exelify_results.py")

        file.write("run_commands = " + json.dumps(all_commands, indent=4))

        file.write("\n")
        file.write(INVOKE_COMMAND)

    subprocess.Popen(["black", "run.py"]).communicate()


if __name__ == "__main__":
    # python generate_run_all_experiments.py --model_name=EleutherAI/gpt-neo-125m
    # python generate_run_all_experiments.py --model_name=EleutherAI/gpt-j-6B
    parser = argparse.ArgumentParser(
        description="Generate run_all_experiments.sh script."
    )
    parser.add_argument(
        "--model_name",
        type=str,
        required=True,
        help="Model name to use for all experiments.",
    )
    args = parser.parse_args()

    main(args.model_name)
